<lexer>
  <config>
    <name>XQL</name>
    <alias>xql</alias>
    <alias>cortex</alias>
    <alias>xsiam</alias>
    <filename>*.xql</filename>
    <mime_type>text/x-xql</mime_type>
    <case_insensitive>true</case_insensitive>
    <ensure_nl>true</ensure_nl>
  </config>
  <rules>
    <!-- Double-quoted string state -->
    <state name="string-double">
      <rule pattern="\\[\\&#34;nrt]">
        <token type="LiteralStringEscape"/>
      </rule>
      <rule pattern="[^\\&#34;]+">
        <token type="LiteralString"/>
      </rule>
      <rule pattern="&#34;">
        <token type="LiteralString"/>
        <pop depth="1"/>
      </rule>
    </state>

    <!-- Single-quoted string state -->
    <state name="string-single">
      <rule pattern="\\[\\&#39;nrt]">
        <token type="LiteralStringEscape"/>
      </rule>
      <rule pattern="[^\\&#39;]+">
        <token type="LiteralString"/>
      </rule>
      <rule pattern="&#39;">
        <token type="LiteralString"/>
        <pop depth="1"/>
      </rule>
    </state>

    <!-- Ingest rule state -->
    <state name="ingest-rule">
      <rule pattern="\]">
        <token type="CommentPreproc"/>
        <pop depth="1"/>
      </rule>
      <rule pattern="(vendor|product|target_dataset|no_hit)\b">
        <token type="NameAttribute"/>
      </rule>
      <rule pattern="=">
        <token type="Operator"/>
      </rule>
      <rule pattern=",">
        <token type="Punctuation"/>
      </rule>
      <rule pattern="[a-zA-Z_][a-zA-Z0-9_]*">
        <token type="LiteralString"/>
      </rule>
      <rule pattern="\s+">
        <token type="TextWhitespace"/>
      </rule>
    </state>

    <!-- Root state -->
    <state name="root">
      <!-- Whitespace -->
      <rule pattern="\s+">
        <token type="TextWhitespace"/>
      </rule>

      <!-- Single-line comments -->
      <rule pattern="//[^\n]*">
        <token type="CommentSingle"/>
      </rule>

      <!-- Ingest rules: [ingest:...] -->
      <rule pattern="\[ingest:">
        <token type="CommentPreproc"/>
        <push state="ingest-rule"/>
      </rule>

      <!-- Double-quoted strings -->
      <rule pattern="&#34;">
        <token type="LiteralString"/>
        <push state="string-double"/>
      </rule>

      <!-- Single-quoted strings -->
      <rule pattern="&#39;">
        <token type="LiteralString"/>
        <push state="string-single"/>
      </rule>

      <!-- Numbers: floats first, then integers -->
      <rule pattern="-?[0-9]+\.[0-9]+([eE][+-]?[0-9]+)?">
        <token type="LiteralNumberFloat"/>
      </rule>
      <rule pattern="-?[0-9]+">
        <token type="LiteralNumberInteger"/>
      </rule>

      <!-- Stage keywords -->
      <rule pattern="(config|filter|alter|comp|sort|dedup|join|fields|dataset|preset|limit|arrayexpand|union|tag|search|graph|table|pivot|transaction|timeshift|windowcomp|iploc|getrole|usernorm|highlight|replacenull|datamodel|top|call|bin|ref|colddataset|hl|view|span|bins|dedupbyjoin|aihelper|suffix)\b">
        <token type="Keyword"/>
      </rule>

      <!-- Clause keywords -->
      <rule pattern="(by|as|asc|desc|type|inner|outer|left|right|timeframe|between)\b">
        <token type="Keyword"/>
      </rule>

      <!-- Boolean operators -->
      <rule pattern="(and|or|not)\b">
        <token type="OperatorWord"/>
      </rule>

      <!-- Boolean/null constants -->
      <rule pattern="(true|false|null)\b">
        <token type="KeywordConstant"/>
      </rule>

      <!-- Set operators (word-based, longer patterns first) -->
      <rule pattern="(not\s+in|not\s+contains|not\s+incidr6|not\s+incidr)\b">
        <token type="OperatorWord"/>
      </rule>
      <rule pattern="(in|contains|incidr6|incidr)\b">
        <token type="OperatorWord"/>
      </rule>

      <!-- Aggregation functions (followed by parenthesis) -->
      <rule pattern="(approx_count|approx_quantiles|approx_top|avg|count_distinct|count|earliest|first|last|latest|list|max|median|min|stddev_population|stddev_sample|sum|values|var)(?=\s*\()">
        <token type="NameFunction"/>
      </rule>

      <!-- Scalar functions (followed by parenthesis) -->
      <rule pattern="(add|arraycreate|arrayconcat|arraydistinct|arrayfilter|arrayindex|arrayindexof|arraymap|arraystring|array_all|array_any|array_length|bitwise_and|bitwise_or|bitwise_sleft|bitwise_xor|ceil|coalesce|concat|convert_from_base_64|convert_to_base_64|current_time|date_floor|divide|extract_time|extract_url_host|extract_url_pub_suffix|extract_url_registered_domain|floor|format_string|format_timestamp|if|incidr|incidr6|incidrlist|int_to_ip|ip_to_int|is_ipv4|is_known_private_ipv4|json_extract|json_extract_array|json_extract_scalar|json_extract_scalar_array|json_path_extract|len|lowercase|ltrim|md5|multiply|object_create|object_merge|parse_epoch|parse_timestamp|pow|regexcapture|replex|round|rtrim|safe_ip_to_int|sha1|sha256|sha512|split|string_count|subtract|timestamp_diff|timestamp_seconds|to_boolean|to_epoch|to_float|to_integer|to_json_string|to_number|to_string|to_timestamp|trim|uppercase|wildcard_match)(?=\s*\()">
        <token type="NameFunction"/>
      </rule>

      <!-- Arrow operator for JSON field access -->
      <rule pattern="-&gt;">
        <token type="Operator"/>
      </rule>

      <!-- Comparison operators (multi-char first) -->
      <rule pattern="!~=|~=|!=|&lt;=|&gt;=|&lt;|&gt;|=">
        <token type="Operator"/>
      </rule>

      <!-- ENUM access: ENUM.VALUE -->
      <rule pattern="([A-Z][A-Z0-9_]*)(\.)([A-Z][A-Z0-9_]*)">
        <bygroups>
          <token type="NameConstant"/>
          <token type="Punctuation"/>
          <token type="NameConstant"/>
        </bygroups>
      </rule>

      <!-- Field names starting with underscore (system fields) -->
      <rule pattern="_[a-zA-Z][a-zA-Z0-9_]*">
        <token type="NameAttribute"/>
      </rule>

      <!-- Dataset patterns with wildcards -->
      <rule pattern="[a-zA-Z][a-zA-Z0-9_]*\*">
        <token type="LiteralString"/>
      </rule>

      <!-- General identifiers -->
      <rule pattern="[a-zA-Z_][a-zA-Z0-9_]*">
        <token type="Name"/>
      </rule>

      <!-- Pipe operator -->
      <rule pattern="\|">
        <token type="Punctuation"/>
      </rule>

      <!-- Punctuation -->
      <rule pattern="[(),\[\]{}:;]">
        <token type="Punctuation"/>
      </rule>

      <!-- Arithmetic operators -->
      <rule pattern="[+\-*/%]">
        <token type="Operator"/>
      </rule>
    </state>
  </rules>
</lexer>
